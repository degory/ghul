namespace Syntax is
    namespace Parser is
        use System;
        use Generic;
        use Logging;
        use Source;
        class CONTEXT  is
            last_error_location: LOCATION;
            last_error_message: String;
            speculative_parse_tokens: Vector[Lexical.TOKEN_PAIR];
            allow_tuple_element: bool public;
            tokenizer: Lexical.TOKENIZER;
            logger: LOGGER;
            init(tokenizer: Lexical.TOKENIZER, logger: LOGGER) -> void is
                self.tokenizer = tokenizer;
                self.logger = logger;
                self.tokenizer.next();
                last_error_location = self.location;
                last_error_message = "";
            si

            next_token() -> bool is
                var result = tokenizer.next();
                if speculative_parse_tokens != null then
                    speculative_parse_tokens.add(current);
                fi
                return result;
            si

            current: Lexical.TOKEN_PAIR is
                return tokenizer.current;
            si

            write_token(token: Lexical.TOKEN_PAIR) -> void is
                tokenizer.write_token(token);
                next_token();
            si

            write_tokens(tokens: Iterable[Lexical.TOKEN_PAIR]) -> void is
                tokenizer.write_tokens(tokens);
                next_token();
            si

            mark() -> void is
                assert(speculative_parse_tokens == null, "cannot start nested speculative parse");
                speculative_parse_tokens = new Vector[Lexical.TOKEN_PAIR]();
                speculative_parse_tokens.add(current);
            si

            commit() -> void is
                assert(speculative_parse_tokens != null, "cannot commit: not in speculative parse");
                speculative_parse_tokens = null;
            si

            backtrack() -> void is
                assert(speculative_parse_tokens != null, "cannot backtrack: not in speculative parse");
                write_tokens(speculative_parse_tokens);
                speculative_parse_tokens = null;
            si

            location_and_next() -> LOCATION is
                var result = location;
                next_token();
                return result;
            si

            skip_token(tokens: List[Lexical.TOKEN], message: String) -> void is
                var start = location;
                do
                    if is_end_of_file then
                        error(start..location, "%: expected %" % [message, Lexical.TOKEN_NAMES[current_token]]: Object );
                        return;
                    elif tokens.contains(current_token) then
                        error(start..location, "%: expected %" % [message, Lexical.TOKEN_NAMES[current_token]]: Object );
                        next_token();
                        return;
                    else
                        next_token();
                    fi
                od
            si

            skip_token(token: Lexical.TOKEN, message: String) -> void is
                var t = new Vector[Lexical.TOKEN]();
                t.add(token);
                skip_token(t, message);
            si

            location: LOCATION is
                return tokenizer.current.location;
            si

            current_token: Lexical.TOKEN is
                return tokenizer.current.token;
            si

            current_string: String is
                return tokenizer.current.string;
            si

            is_end_of_file: bool is
                return tokenizer.is_end_of_file;
            si

            current_token_name: String is
                var result = Lexical.TOKEN_NAMES[current_token];
                if result == null then
                    result = "unknown";
                fi
                if current_string!=null && current_string!~result then
                    result = result + ' ' + current_string;
                fi
                return result;
            si

            expect_token(token: Lexical.TOKEN, message: String) -> bool public is
                if current_token != token then
                    error(location, "%: expected % but found %" % [message, Lexical.TOKEN_NAMES[token], current_token_name]: Object );
                    return false;
                else
                    return true;
                fi
            si

            expect_token(token: Lexical.TOKEN) -> bool public is
                return expect_token(token, "syntax error");
            si

            expect_token(tokens: List[Lexical.TOKEN], message: String) -> bool public is
                if !tokens.contains(current_token) then
                    error(location, "%: expected % but found %" % [message, Lexical.TOKEN_NAMES[tokens], current_token_name]: Object );
                    return false;
                else
                    return true;
                fi
            si

            expect_token(tokens: List[Lexical.TOKEN]) -> bool public is
                return expect_token(tokens, "syntax error");
            si

            next_token(token: Lexical.TOKEN, message: String) -> bool public is
                if expect_token(token, message) then
                    next_token();
                    return true;
                fi
            si

            next_token(tokens: List[Lexical.TOKEN], message: String) -> bool public is
                if expect_token(tokens, message) then
                    next_token();
                    return true;
                fi
            si

            next_token(token: Lexical.TOKEN) -> bool public is
                return next_token(token, "syntax error");
            si

            next_token(tokens: List[Lexical.TOKEN]) -> bool public is
                return next_token(tokens, "syntax error");
            si

            error(location: LOCATION, message: String) -> void public is
                if location!~last_error_location || message!~last_error_message then
                    last_error_location = location;
                    last_error_message = message;
                    logger.error(location, message);
                elif !is_end_of_file then
                    next_token();
                else
                    throw new Exception("give up");
                fi
            si

        si
    si
si
