namespace Lexical is
    use Collections;

    use Debugging;

    trait TokenSource is
        read_token() -> TOKEN_PAIR;
        expect_format_specifier();
    si

    class RECENT_BACKTRACK_STORE is
        _recent_backtracks: ((from: int, to: int), (from: int, to: int), (from: int, to: int), (from: int, to: int), (from: int, to: int));

        init() is
        si

        record_backtrack(from: int, to: int) is
            let count = 0;

/*
            // FIXME generates invalid IL - suspect
            // it's not dereferencing `1
            if _recent_backtracks.`1 == from_to then
                debug("seen @ 1");
                count = count + 1;
            fi
*/

            if _recent_backtracks.`0.from == from /\
                _recent_backtracks.`0.to == to
            then
                count = count + 1;
            fi

            if _recent_backtracks.`1.from == from /\
                _recent_backtracks.`1.to == to
            then
                count = count + 1;
            fi

            if _recent_backtracks.`2.from == from /\
                _recent_backtracks.`2.to == to
            then
                count = count + 1;
            fi

            if _recent_backtracks.`3.from == from /\
                _recent_backtracks.`3.to == to
            then
                count = count + 1;
            fi

            if _recent_backtracks.`4.from == from /\
                _recent_backtracks.`4.to == to
            then
                count = count + 1;
            fi

            if count > 1 then
                debug_always("speculative parsing loop backtracking from {from} to {to} ({_recent_backtracks}) from {System.Diagnostics.StackTrace().to_string().replace_line_endings(" ")}");
                throw new System.Exception("speculative parsing loop backtracking from {from} to {to} ({_recent_backtracks})");
            elif count > 0 then
                debug_always("possible speculative parsing loop backtracking from {from} to {to} ({_recent_backtracks}) from {System.Diagnostics.StackTrace().to_string().replace_line_endings(" ")}");
            fi

            let from_to = (from, to);

            _recent_backtracks = (
                _recent_backtracks.`1, 
                _recent_backtracks.`2, 
                _recent_backtracks.`3, 
                _recent_backtracks.`4, 
                from_to
            );
        si
    si

    class TOKEN_LOOKAHEAD is
        _queue: TOKEN_QUEUE;
        _mark_stack: STACK[int];
        _recent_backtracks: RECENT_BACKTRACK_STORE;

        _tokenizer: TokenSource;

        init(
            queue: TOKEN_QUEUE,
            tokenizer: TokenSource
        ) is
            _mark_stack = STACK[int]();
            _queue = queue;
            _tokenizer = tokenizer;
            _recent_backtracks = RECENT_BACKTRACK_STORE();
        si

        // when we first start speculating, we need to tell
        // the token queue to mark the read position, because
        // we must not write past it
        speculate() is
            if _mark_stack.count == 0 then
                _queue.speculate_enter();
            fi

            // FIXME: we can get the token from the previous slot
            // in the queue
            _mark_stack.push(_queue.mark());
        si

        backtrack() -> TOKEN_PAIR is
            // we want to carry on reading tokens from the last
            // saved read position, effectively undoing the
            // speculation

            let current = _queue.get_read_index();
            let mark = _mark_stack.pop();

            _recent_backtracks.record_backtrack(current, mark);

            _queue.release(mark);

            if _mark_stack.count == 0 then
                _queue.speculate_exit();
            fi

            return _queue.last();
        si

        commit() is
            // we want to discard the saved read position, and
            // carry on reading tokens from the current position

            _mark_stack.pop();

            // if we have no more saved read positions, then we
            // can tell the token queue it's safe to write past
            // the speculative read position again
            if _mark_stack.count == 0 then
                _queue.speculate_exit();
            fi
        si

        expect_format_specifier() is
            _tokenizer.expect_format_specifier();
        si

        read_token() -> TOKEN_PAIR is
            if !_queue.avail then
                let result = _tokenizer.read_token();

                _queue.enqueue(result);
            fi

            return _queue.dequeue(); 
        si
    si
si