namespace Lexical is
    use Collections;

    use Logging;

    trait TokenSource is
        read_token() -> TOKEN_PAIR;
        expect_format_specifier();
    si

    class TOKEN_LOOKAHEAD is
        _queue: TOKEN_QUEUE;
        _mark_stack: STACK[int];

        _tokenizer: TokenSource;

        init(
            queue: TOKEN_QUEUE,
            tokenizer: TokenSource
        ) is
            _mark_stack = new STACK[int]();
            _queue = queue;
            _tokenizer = tokenizer;
        si

        // when we first start speculating, we need to tell
        // the token queue to mark the read position, because
        // we must not write past it
        speculate(prev_token: TOKEN_PAIR) is
            if _mark_stack.count == 0 then
                _queue.speculate_enter();
            fi

            // FIXME: we can get the token from the previous slot
            // in the queue
            _mark_stack.push(_queue.mark());
        si

        backtrack() -> TOKEN_PAIR is
            // we want to carry on reading tokens from the last
            // saved read position, effectively undoing the
            // speculation

            let mark = _mark_stack.pop();

            _queue.release(mark);

            if _mark_stack.count == 0 then
                _queue.speculate_exit();
            fi

            return _queue.last();
        si

        commit() is
            // we want to discard the saved read position, and
            // carry on reading tokens from the current position

            _mark_stack.pop();

            // if we have no more saved read positions, then we
            // can tell the token queue it's safe to write past
            // the speculative read position again
            if _mark_stack.count == 0 then
                _queue.speculate_exit();
            fi
        si

        expect_format_specifier() is
            _tokenizer.expect_format_specifier();
        si

        read_token() -> TOKEN_PAIR is
            if !_queue.avail then
                let result = _tokenizer.read_token();

                _queue.enqueue(result);
            fi

            return _queue.dequeue(); 
        si
    si
si