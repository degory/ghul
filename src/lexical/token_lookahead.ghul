namespace Lexical is
    use Collections;

    use Logging;

    trait TokenSource is
        read_token() -> TOKEN_PAIR;
    si

    class TOKEN_LOOKAHEAD is
        _queue: TOKEN_QUEUE;
        _mark_stack: STACK[(mark: int, prev_token: TOKEN_PAIR)];

        _tokenizer: TokenSource;

        init(tokenizer: TokenSource) is
            _queue = new TOKEN_QUEUE();
            _mark_stack = new STACK[(int, TOKEN_PAIR)]();

            _tokenizer = tokenizer;
        si

        // when we first start speculating, we need to tell
        // the token queue to mark the read position, because
        // we must not write past it
        speculate(prev_token: TOKEN_PAIR) is
            debug("TL speculating...");

            if _mark_stack.count == 0 then
                debug("TL queue speculate enter");
                _queue.speculate_enter();
            fi

            // FIXME: we can get the token from the previous slot
            // in the queue

            debug("TL pushing mark");
            _mark_stack.push((_queue.mark(), prev_token));
        si

        backtrack() -> TOKEN_PAIR is
            debug("TL backtracking...");

            // we want to carry on reading tokens from the last
            // saved read position, effectively undoing the
            // speculation

            let mark_prev_token = _mark_stack.pop();

            debug("TL popped mark: {mark_prev_token.mark} and token {mark_prev_token.prev_token.to_short_string()}");

            _queue.release(mark_prev_token.mark);

            debug("TL released to mark");

            if _mark_stack.count == 0 then
                debug("TL queue speculate exit");
                _queue.speculate_exit();
            fi

            debug("TL returning token {mark_prev_token.prev_token.to_short_string()}");

            // FIXME: we can get the token from the previous slot
            // in the queue
            return mark_prev_token.prev_token;
        si

        commit() is
            debug("TL committing...");

            // we want to discard the saved read position, and
            // carry on reading tokens from the current position

            _mark_stack.pop();

            debug("TL popped mark");

            // if we have no more saved read positions, then we
            // can tell the token queue it's safe to write past
            // the speculative read position again
            if _mark_stack.count == 0 then
                debug("TL queue speculate exit");
                
                _queue.speculate_exit();
            fi

            debug("TL committed");
        si

        read_token() -> TOKEN_PAIR is
            debug("TL reading token...");
 
            // if _mark_stack.count == 0 then
            //     debug("TL not speculating: read token from input...");

            //     return _tokenizer.read_token();
            // fi

            // debug("TL maybe read token from queue...");

            if !_queue.avail then
                debug("TL queue empty: read token from input...");

                let result = _tokenizer.read_token();

                debug("TL read token {result.to_short_string()}");

                _queue.enqueue(result);
            else
                debug("TL will read token from queue...");
            fi

            return _queue.dequeue(); 
        si
    si
si