namespace Lexical is
    use Collections;

    use Logging;

    class TOKEN_QUEUE is
        _buffer: LIST[TOKEN_PAIR];
        _speculate_index: int;
        _read_index: int; // points at the last token read
        _write_index: int; // points at the last token written
        _size: int;

        _count: int => (_write_index - _read_index + _size) ∩ (_size - 1);

        count: int is
            let result = (_write_index - _read_index + _size) ∩ (_size - 1);

            debug_always("count is ({_write_index} - {_read_index} + {_size}) mod {_size} = {result}");

            return result;
        si
         
        avail: bool => count > 0;

        is_speculating: bool => _speculate_index != -1;

        _peek_offset(index: int) -> int =>
            (_read_index + index) ∩ (_size - 1);

        _next_index(index: int) -> int =>
            (index + 1) ∩ (_size - 1);

        _prev_index(index: int) -> int =>
            (index - 1) ∩ (_size - 1);

        init(size: int) is
            assert size > 0 else "token queue size must be greater than 0";
            assert (size ∩ (size - 1)) == 0 else "token queue size must be a power of 2";

            _size = size;
            _read_index = 0;
            _write_index = 0;
            _speculate_index = -1;

            _buffer = new LIST[TOKEN_PAIR](_size);

            // .NET can be very annoying sometimes...

            for i in 0.._size do
                _buffer.add(null);
            od

            debug_always("token queue size {_size} count {_count} initialized");
        si

        speculate_enter() is
            assert _speculate_index == -1 else "already speculating";
            _speculate_index = _read_index;
        si

        speculate_exit() is
            assert _speculate_index != -1 else "not speculating";
            _speculate_index = -1;
        si

        mark() -> int is
            assert _speculate_index != -1 else "not speculating";

            debug_always("return read index {_read_index} as mark");

            return _read_index;
        si

        release(index: int) is
            assert _speculate_index != -1 else "not speculating";
            _read_index = index;
        si

        last() -> TOKEN_PAIR is
            // assert _read_index != _write_index else "token queue underflow";

            debug_always("last token read index {_read_index} write index {_write_index} count {_count}");

            let result = _buffer[_read_index];

            if result? then
                debug_always("last token read {result} at {_read_index}");
            else
                debug_always("last token read (NULL) at {_read_index}");
            fi

            return result;
        si

        enqueue(token: TOKEN_PAIR) is
            debug_always("\nbefore enqueue count {_count} read {_read_index} write {_write_index} speculate {_speculate_index}");

            let old_index = _read_index;

            _write_index = _next_index(_write_index); 

            assert _write_index != _read_index /\ _write_index != _speculate_index else "token queue overflow";
            // assert _count < _size else "token queue overflow";

            debug_always("enqueue token write index {old_index} + 1 -> write index, write {token} at {_write_index} count {_count}");

            _buffer[_write_index] = token;

            debug_always("after enqueue count {_count} read {_read_index} write {_write_index} speculate {_speculate_index}\n");
        si

        dequeue() -> TOKEN_PAIR is
            debug_always("\nbefore dequeue count {_count} read {_read_index} write {_write_index} speculate {_speculate_index}");

            assert _read_index != _write_index else "token queue underflow";

            let old_index = _read_index;

            //  assert _count > 0 else "token queue underflow";

            _read_index = _next_index(_read_index); 

            // assert _read_index != _write_index else "token queue underflow";

            // if _read_index == _write_index then
            //     debug_always("dequeue token read index {old_index} + 1 -> read index, read (UNDERFLOW) at {_read_index} count {_count}");
            //     return null;
            // fi

            let result = _buffer[_read_index];

            if result? then
                debug_always("dequeue token read index {old_index} + 1 -> read index, read {result} at {_read_index} count {_count}");
            else
                debug_always("dequeue token read index {old_index} + 1 -> read index, read (NULL) at {_read_index} count {_count}");
            fi

            debug_always("after dequeue count {_count} read {_read_index} write {_write_index} speculate {_speculate_index}\n");

            return result;
        si
    si
si