namespace Lexical is
    use Collections;

    use Logging;

    class TOKEN_QUEUE is
        _buffer: LIST[TOKEN_PAIR];
        _speculate_index: int;
        _read_index: int; // points at the last token read
        _write_index: int; // points at the last token written
        _size: int;

        count: int is
            let result = (_write_index - _read_index + _size) ∩ (_size - 1);

            return result;
        si
         
        avail: bool => count > 0;

        is_speculating: bool => _speculate_index != -1;

        _peek_offset(index: int) -> int =>
            (_read_index + index) ∩ (_size - 1);

        _next_index(index: int) -> int =>
            (index + 1) ∩ (_size - 1);

        _prev_index(index: int) -> int =>
            (index - 1) ∩ (_size - 1);

        init(size: int) is
            assert size > 0 else "token queue size must be greater than 0";
            assert (size ∩ (size - 1)) == 0 else "token queue size must be a power of 2";

            _size = size;
            _read_index = 0;
            _write_index = 0;
            _speculate_index = -1;

            _buffer = new LIST[TOKEN_PAIR](_size);

            // .NET can be very annoying sometimes...

            for i in 0.._size do
                _buffer.add(null);
            od
        si

        speculate_enter() is
            assert _speculate_index == -1 else "already speculating";
            _speculate_index = _read_index;
        si

        speculate_exit() is
            assert _speculate_index != -1 else "not speculating";
            _speculate_index = -1;
        si

        get_read_index() -> int => _read_index;

        mark() -> int is
            assert _speculate_index != -1 else "not speculating";

            return _read_index;
        si

        release(index: int) is
            assert _speculate_index != -1 else "not speculating";
            _read_index = index;
        si

        last() -> TOKEN_PAIR is
            let result = _buffer[_read_index];

            return result;
        si

        enqueue(token: TOKEN_PAIR) is
            let new_write_index = _next_index(_write_index); 

            assert new_write_index != _read_index /\ new_write_index != _speculate_index else "token queue overflow";

            _write_index = new_write_index;

            _buffer[_write_index] = token;
        si

        dequeue() -> TOKEN_PAIR is
            assert _read_index != _write_index else "token queue underflow";

            _read_index = _next_index(_read_index); 

            let result = _buffer[_read_index];

            return result;
        si
    si
si