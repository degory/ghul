namespace Syntax.Parsers.Expressions is
    use IO.Std;

    use Source;
    use Logging;

    class SECONDARY: Base[Trees.Expressions.Expression] is
        identifier_parser: Parser[Trees.Identifiers.Identifier];
        type_parser: Parser[Trees.TypeExpressions.TypeExpression];
        type_list_parser: Parser[Trees.TypeExpressions.LIST];
        expression_parser: Parser[Trees.Expressions.Expression];
        expression_primary_parser: Parser[Trees.Expressions.Expression];
        expression_list_parser: Parser[Trees.Expressions.LIST];
        body_parser: Parser[Trees.Bodies.Body];
        description: string => "secondary expression";
        
        init(
            identifier_parser: Parser[Trees.Identifiers.Identifier],
            type_parser: Parser[Trees.TypeExpressions.TypeExpression],
            type_list_parser: Parser[Trees.TypeExpressions.LIST],
            expression_parser: Parser[Trees.Expressions.Expression],
            expression_primary_parser: Parser[Trees.Expressions.Expression],
            expression_list_parser: Parser[Trees.Expressions.LIST],
            body_parser: Parser[Trees.Bodies.Body]
        )
        is
            super.init();

            self.identifier_parser = identifier_parser;
            self.type_parser = type_parser;
            self.type_list_parser = type_list_parser;
            self.expression_parser = expression_parser;
            self.expression_primary_parser = expression_primary_parser;
            self.expression_list_parser = expression_list_parser;
            self.body_parser = body_parser;
        si

        parse(context: CONTEXT) -> Trees.Expressions.Expression is
            let use tokenizer_state = context.tokenizer_speculate_then_commit();

            let start = context.location;
            let result: Trees.Expressions.Expression = expression_primary_parser.parse(context);

            let previous_left: Trees.Expressions.Expression;
            let previous_identifier: Trees.Identifiers.Identifier;

            do
                case context.current.token
                when Lexical.TOKEN.PAREN_OPEN:
                    context.next_token();
                    let arguments: Trees.Expressions.LIST;
                    if context.current.token != Lexical.TOKEN.PAREN_CLOSE then
                        arguments = expression_list_parser.parse(context);
                    else
                        arguments = new Trees.Expressions.LIST(context.location, new Collections.LIST[Trees.Expressions.Expression]());
                    fi
                    result = new Trees.Expressions.CALL(start::context.location, result, arguments);
                    context.next_token(Lexical.TOKEN.PAREN_CLOSE, syntax_error_message);

                when Lexical.TOKEN.SQUARE_OPEN:
                    context.next_token();

                    let use debug_dispose = debug_enter();
                    debug("parsing ambiguous index expression / generic type expression");

                    let done = false;

                    let left: Trees.Expressions.Expression;
                    let identifier: Trees.Identifiers.Identifier;

                    if result.is_member then
                        left = previous_left;
                        identifier = previous_identifier;

                    elif result.is_identifier then
                        left = null;
                        identifier = result.try_copy_as_identifer();
                    fi

                    if identifier? then
                        debug("left hand side is a member expression or an identifier, try to parse arguments as type expressions");

                        let use tokenizer_state = context.tokenizer_speculate_then_commit();
                        let use logger_state = context.logger_speculate_then_commit();
    
                        let type_arguments = type_list_parser.parse(context);

                        debug("type arguments: {type_arguments}");

                        if type_arguments? /\ !type_arguments.is_poisoned /\ context.next_token(Lexical.TOKEN.SQUARE_CLOSE) then
                            debug("type arguments are valid types");

                            let index_expression: Trees.Expressions.Expression;

                            if type_arguments.count == 1 then
                                let index = type_arguments.elements[0].try_copy_as_value_expression();
                                if index? then
                                    index_expression = new Trees.Expressions.INDEX(start::context.location, result, index);
                                fi
                            fi;

                            // debug("generic type expression: {type_expression}");

                            done = true;

                            if index_expression? then
                                result = new Trees.Expressions.AMBIGUOUS_EXPRESSION(
                                    start::context.location,
                                    index_expression,
                                    left,
                                    identifier,
                                    type_arguments
                                );
                            else
                                result = new Trees.Expressions.GENERIC_APPLICATION(
                                    start::context.location,
                                    left,
                                    identifier,
                                    type_arguments
                                );                               
                            fi

                            debug("result is {result}");

                            tokenizer_state.commit();
                            logger_state.commit();

                            // FIXME: continue generates incorrect code here
                            // continue;
                        fi

                        tokenizer_state.backtrack_if_speculating();
                        logger_state.backtrack_if_speculating();
                    else
                        debug("left hand side {result} ({result.get_type()} is not a member expression, trying to parse as index expression");
                    fi

                    if !done then
                        debug("parsing as index expression");

                        let index = expression_parser.parse(context);

                        result = new Trees.Expressions.INDEX(start::context.location, result, index);

                        debug("result is index expression {result}");

                        context.next_token(Lexical.TOKEN.SQUARE_CLOSE, syntax_error_message);
                    fi

                when Lexical.TOKEN.DOT:
                    let completion_target_start = context.location;

                    context.next_token();

                    if
                        context.current.token == Lexical.TOKEN.IDENTIFIER
                    then
                        let member = identifier_parser.parse(context);

                        previous_left = result;
                        previous_identifier = member;

                        result = new Trees.Expressions.MEMBER(start::member.location, result, member, completion_target_start::member.location);
                    else
                        context.expect_token(Lexical.TOKEN.IDENTIFIER);                        
                        result = new Trees.Expressions.MEMBER(start..context.location, result, null, completion_target_start::context.location);
                    fi

                when Lexical.TOKEN.ARROW_THIN, Lexical.TOKEN.ARROW_FAT, Lexical.TOKEN.IS, Lexical.TOKEN.REC:
                    // we could be in a global function or in a method. If the left part looks like it could be a function or method definition
                    // then it's an error and we need to recover. 

                    // we'll need a heuristic to try to decide if the user is trying to define a nested function or if they've missed off a closing `si`
                    // and actually this is a method definition (if we're in a classy context) or a global function definition (if we're not in a classy context)

                    let is_nested_function_definition = false;

                    if result.could_be_nested_function_definition /\ tokenizer_state.is_speculating then
                        // TODO need same logic but for nested within a global function
                        if context.in_member then
                            if result.location.start_column > context.member_indent then
                                // probably an attempt at nesting a named function definition
                                is_nested_function_definition = true;
                            elif 
                                result.location.start_column <= context.member_indent /\
                                result.location.start_column > context.global_indent    
                            then
                                // probably a missing `si` in a preceding member definition
                                context.error(result.location, "expected 'si' after member definition");

                                tokenizer_state.backtrack();

                                throw new UNWIND_TO_MEMBER_EXCEPTION(null);
                            fi
                        elif context.in_global_function then
                            if result.location.start_column > context.global_indent then
                                // probably an attempt at nesting a named function definition
                                is_nested_function_definition = true;
                            else
                                // probably a missing `si` in a preceding member definition
                                context.error(result.location, "expected 'si' after member definition");

                                tokenizer_state.backtrack();

                                throw new UNWIND_TO_GLOBAL_EXCEPTION(null);
                            fi
                        elif context.in_classy then
                            // not clear how we might have ended up here
                            tokenizer_state.backtrack();

                            throw new UNWIND_TO_GLOBAL_EXCEPTION(null);
                        fi
                    fi

                    // it's unlikely to be new member or new global function definition, so we should
                    // parse it as a function literal, even if it has a name or is otherwise garbled.
                    // In particular, if has a block body delimited with with is / si, then we want to
                    // consume that block, otherwise our view of the block structure will get out of sync
                    // and we'll think we've let the enclosing function or method when we reach the closing
                    // `si` of the function literal

                    let should_poison = false;
                    
                    if result.could_be_nested_function_definition then
                        should_poison = true;
                        context.error(result.location, "nested function definition");
                    elif !result.could_be_formal_argument then
                        should_poison = true;
                        context.error(result.location, "expected function literal formal arguments");
                    fi
    
                    let type_expression: Trees.TypeExpressions.TypeExpression;
                    let arguments: Trees.Expressions.LIST;

                    if context.current.token == Lexical.TOKEN.ARROW_THIN then
                        context.next_token();
                        type_expression = type_parser.parse(context);
                        type_expression.check_is_not_reference(context.logger, "function cannot return a reference");
                    else
                        type_expression = new Trees.TypeExpressions.INFER(start::result.location);
                    fi

                    if context.expect_token([Lexical.TOKEN.ARROW_FAT, Lexical.TOKEN.IS, Lexical.TOKEN.REC]) then
                        if should_poison then
                            // error already reported
                            arguments = new Trees.Expressions.LIST(start::result.location, new Collections.LIST[Trees.Expressions.Expression]());                                
                        elif isa Trees.Expressions.TUPLE(result) then
                            arguments = cast Trees.Expressions.TUPLE(result).elements;
                            arguments.rewrite_as_variables();
                        else
                            let elements = new Collections.LIST[Trees.Expressions.Expression]();
                            elements.add(result);
                            arguments = new Trees.Expressions.LIST(start::result.location, elements);
                        fi

                        let is_recursive = 
                            if context.current.token == Lexical.TOKEN.REC then
                                context.next_token();
                                true;
                            else
                                false;
                            fi;

                        let body = body_parser.parse(context);

                        result = 
                            new Trees.Expressions.FUNCTION(
                                start::body.location,
                                arguments,
                                type_expression,
                                body,
                                is_recursive
                            );

                        if should_poison then
                            result.poison();
                        fi

                        return result;
                    else
                        // TODO: is this possible?
                        return new Trees.Expressions.Literals.NONE(start::context.location);
                    fi

                when Lexical.TOKEN.QUESTION:
                    result = new Trees.Expressions.HAS_VALUE(start::context.location, result);
                    tokenizer_state.commit_if_speculating();

                    context.next_token();

                when Lexical.TOKEN.REF:
                    result = new Trees.Expressions.REFERENCE(start::context.location, result);
                    tokenizer_state.commit_if_speculating();

                    context.next_token();

                when Lexical.TOKEN.OPERATOR:
                    tokenizer_state.commit_if_speculating();

                    if context.current_string =~ "|" then
                        let location = context.location;

                        let pipes = new Trees.Identifiers.Identifier(location, "Pipes");
                        let pipe = new Trees.Identifiers.QUALIFIED(location, pipes, "Factory", location, location);
                        let from = new Trees.Identifiers.QUALIFIED(location, pipe, "from", location, location);

                        let function = new Trees.Expressions.IDENTIFIER(location, from);

                        let arguments = new Trees.Expressions.LIST(
                            result.location,
                            [result]
                        );

                        result = 
                            new Trees.Expressions.CALL(
                                start::location,
                                function,
                                arguments
                            );
                            
                        context.next_token();
                    elif context.current_string =~ "!" then
                        result = new Trees.Expressions.UNWRAP(start::context.location, result);

                        context.next_token();
                    else
                        return result;
                    fi

                when Lexical.TOKEN.SQUARE_OPEN_TICK:
                    tokenizer_state.commit_if_speculating();
                    
                    context.next_token();
                    
                    let type_arguments = type_list_parser.parse(context);

                    if result.is_member then
                        result = new Trees.Expressions.GENERIC_APPLICATION(
                            start::context.location,
                            previous_left,
                            previous_identifier,
                            type_arguments
                        );
                    else
                        result.poison();
                        context.error(result.location, "cannot apply type arguments to non-identifier");
                    fi

                    context.next_token(Lexical.TOKEN.SQUARE_CLOSE);
                default
                    return result;
                esac
            od
        si
    si
si
